{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3cb74c",
   "metadata": {},
   "source": [
    "# R8 and R52 text dataset\n",
    "nltk only contains the whole corpus ([docs](https://www.nltk.org/book/ch02.html)) so I built the subsets by hand by following the explanation [here](https://ana.cachopo.org/datasets-for-single-label-text-categorization).\n",
    "\n",
    "The number of docs in the datasets **do not match** the numbers in the Text GCN paper as I got slightly more docs! This might be because the nltk version contains some \"fixed\" docs which incorrectly had multiple or no classes (read explanation). I manually checked some classes with the different numbers and they seemed fine (so all docs had a single class) The classes match at least!\n",
    "\n",
    "Also note that stop-words are already removed (unlike in Text GCN).\n",
    "\n",
    "Since our goal is not to reproduce the paper, I just accepted these things\n",
    "\n",
    "Making a graph dataset out of this is TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ddc58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/mat/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import BucketIterator, Field\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from datasets.reuters_text import R8, R52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b2ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/miniconda3/envs/atcs-project/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "ID = Field(sequential=False, include_lengths=False)\n",
    "TEXT = Field(sequential=True, lower=True, include_lengths=True, batch_first=True)\n",
    "LABEL = Field(sequential=False, include_lengths=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9091d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/miniconda3/envs/atcs-project/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "r52_train, r52_test, r52_val = R52.splits(ID, TEXT, LABEL, val_size=0.1)\n",
    "r8_train,  r8_test, r8_val  = R8.splits(ID, TEXT, LABEL, val_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c839c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R8\n",
      "train size: 4951  instead of 5485\n",
      "test size: 2190  instead of 2189\n",
      "val size: 550\n",
      "R52\n",
      "train size: 5904  instead of 6532\n",
      "test size: 2570  instead of 2568\n",
      "val size: 656\n"
     ]
    }
   ],
   "source": [
    "print('R8')\n",
    "print('train size:', len(r8_train), ' instead of 5485')\n",
    "print('test size:', len(r8_test), ' instead of 2189')\n",
    "print('val size:', len(r8_val))\n",
    "\n",
    "print('R52')\n",
    "print('train size:', len(r52_train), ' instead of 6532')\n",
    "print('test size:', len(r52_test), ' instead of 2568')\n",
    "print('val size:', len(r52_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29c705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID.build_vocab(r52_train)\n",
    "TEXT.build_vocab(r52_train, vectors=GloVe(name='840B', dim=300, max_vectors=10000))\n",
    "LABEL.build_vocab(r52_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28b8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/miniconda3/envs/atcs-project/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "r52_train_iter, r52_test_iter, r52_val_iter = BucketIterator.splits(\n",
    "    (r52_train, r52_test, r52_val), \n",
    "    batch_size=4,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e0700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 4]\n",
      "\t[.id]:[torch.LongTensor of size 4]\n",
      "\t[.text]:('[torch.LongTensor of size 4x489]', '[torch.LongTensor of size 4]')\n",
      "\t[.label]:[torch.LongTensor of size 4]\n",
      "tensor([1666, 2736, 4494, 1235])\n",
      "tensor([ 3,  2, 25,  2])\n",
      "['crude']\n",
      "crude\n",
      "These two labels should be the same: crude == crude\n",
      "(tensor([[2396,  380, 4430,  ...,    1,    1,    1],\n",
      "        [ 949,   20,   21,  ..., 1286,  928,    2],\n",
      "        [ 235,   99,  793,  ...,    1,    1,    1],\n",
      "        [8752, 5676,   10,  ...,    1,    1,    1]]), tensor([111, 489,  40,  22]))\n",
      "\n",
      "[torchtext.data.batch.Batch of size 4]\n",
      "\t[.id]:[torch.LongTensor of size 4]\n",
      "\t[.text]:('[torch.LongTensor of size 4x899]', '[torch.LongTensor of size 4]')\n",
      "\t[.label]:[torch.LongTensor of size 4]\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([4, 4, 4, 4])\n",
      "(tensor([[1989, 1201, 3241,  ...,    4, 1065,    2],\n",
      "        [ 130,  629,  891,  ...,    1,    1,    1],\n",
      "        [ 239,  187, 1475,  ...,    1,    1,    1],\n",
      "        [ 130,  629,  891,  ...,    1,    1,    1]]), tensor([899, 233, 257, 233]))\n",
      "\n",
      "[torchtext.data.batch.Batch of size 4]\n",
      "\t[.id]:[torch.LongTensor of size 4]\n",
      "\t[.text]:('[torch.LongTensor of size 4x101]', '[torch.LongTensor of size 4]')\n",
      "\t[.label]:[torch.LongTensor of size 4]\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 11,  1,  1])\n",
      "(tensor([[    0,    10,  3867,     0,  1127,   332,    20,    21,    19,     0,\n",
      "            57,    26,    10,     4,    20,    21,    19,  3867,  1008,     2,\n",
      "             0,    57,    26,    77,   857,    27,   155,   338,    14,   287,\n",
      "           332,     5,   144,     5,     4,  1765,  5008,  2391,     5,  1144,\n",
      "           579,    57,     2,     0,     9,    17,    10,     4,     0,   497,\n",
      "            38,   363,   804,     8,   133,    23,  1550,   167,     7,     4,\n",
      "          5008,  2391,     2,     0,  2722,   287,    33,     3,    56,  1122,\n",
      "            35,     8,    64,   121,     3,    17,    49,  1781,    54,   569,\n",
      "           133,    11,    15,     5,   242,     6,  1144,     2,     0,   416,\n",
      "          1144,   579,    57,   179,    71,    28,     3,     4,    42,     9,\n",
      "             2],\n",
      "        [14502,  3724,    57,   702,   275,  3351, 14502,  3724,    57,     9,\n",
      "           428,  1180,    27,     4, 13091,  9713,  1091,  1024,     4,   370,\n",
      "            14,  1401, 13275,   137,     8,  6324,     5,   616,  1025,     2,\n",
      "          3351,  5329,    30,    80,    87,     2,   335,  1038,     5,   275,\n",
      "           100,   452,  1163,   137,     8,   704,    14,  3116,  7963,    37,\n",
      "             8,  2670,     5,  1336,     6,   357,  1025,     6,    80,    24,\n",
      "             2,    24,  1038,     5,   275,   100,  1163,   137,     8,   568,\n",
      "            14,  3116,  7963,    37,     8,  2670,     5,   522,     6,  3773,\n",
      "          1025,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,  1838,    20,    21,    19,     0,    26,   305,   822,   135,\n",
      "             0,  1838,    57,     9,    29,   148,   701,    54,   822,   317,\n",
      "           135,     5,    90,    25,   100,    60,     3,    29,   107,   519,\n",
      "             3,   430,    91,   356,     6,   623,     5,   124,    91,   129,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [ 3685,    20,    21,    19, 10330,    26,     6,   374,   276,    18,\n",
      "            13,    67,  3685,    89,    46,     9,    17,   286,     6,   374,\n",
      "           134,    23,     5,     4,   157,    68,     5,    29, 10219,  3286,\n",
      "            89,    46,   159,     6,  3685,    89,   200,     2,     4,    42,\n",
      "             9,    17,  1380,     6,   374,    70,    60,     5, 10219,  3286,\n",
      "            16,   363,   188,  3685,    67,   378,     6,   200,     5,   124,\n",
      "            91,   356,     2,     4,   642,    32,   832,    16,    98,   149,\n",
      "             3,     4,    42,    88,     9,     2,    17,     9,     4, 10219,\n",
      "            67,    38,    82,     7,     4,   137,    14,     4,    14,  2070,\n",
      "            94,   164,     4,  9456,     0,     2,     1,     1,     1,     1,\n",
      "             1]]), tensor([101,  82,  41,  96]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/miniconda3/envs/atcs-project/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import reuters just to prove a point\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "for x in r52_train_iter:\n",
    "    print(x)\n",
    "    print(x.id)\n",
    "    print(x.label)\n",
    "    print(reuters.categories(ID.vocab.itos[x.id[0]]))\n",
    "    print(LABEL.vocab.itos[x.label[0]])\n",
    "    print('These two labels should be the same: {} == {}'.format(\n",
    "        reuters.categories(ID.vocab.itos[x.id[0]])[0],\n",
    "        LABEL.vocab.itos[x.label[0]]))\n",
    "\n",
    "    print(x.text) # Padding is 1\n",
    "    break\n",
    "\n",
    "for x in r52_test_iter:\n",
    "    print(x)\n",
    "    print(x.id)\n",
    "    print(x.label)\n",
    "    print(x.text) # Padding is 1\n",
    "    break\n",
    "    \n",
    "for x in r52_val_iter:\n",
    "    print(x)\n",
    "    print(x.id)\n",
    "    print(x.label)\n",
    "    print(x.text) # Padding is 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1b5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
